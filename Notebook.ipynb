{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGhnXfIKVcHv",
        "colab_type": "text"
      },
      "source": [
        "#**Importing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdfOI23zvN_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing necessary libraries\n",
        "\n",
        "import pandas as pd   # For the DataFrame \n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "#%matplotlib notebook                      # In jupyter run this line to get an interactive plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1JJz7cbe6Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ndf1=pd.read_csv('dataset/anger-ratings-0to1.train.txt',sep='\\t',names=['ind','text','emotion','int'])\n",
        "ndf2=pd.read_csv('datsset/fear-ratings-0to1.train.txt',sep='\\t',names=['ind','text','emotion','int'])\n",
        "ndf3=pd.read_csv('dataset/joy-ratings-0to1.train.txt',sep='\\t',names=['ind','text','emotion','int'])\n",
        "ndf4=pd.read_csv('datset/sadness-ratings-0to1.train.txt',sep='\\t',names=['ind','text','emotion','int'])\n",
        "df1 = ndf1.append(ndf2).append(ndf3).append(ndf4)\n",
        "#df1.pop('ind')\n",
        "df1=df1.sample(frac=1)\n",
        "df1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPOxxStxke0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkj35FummRld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "emotions_set=np.unique(df1['emotion'])\n",
        "print('The Various Emotions are: ',emotions_set,'\\n\\n\\n The Description of the Dataset: \\n ')\n",
        "df1.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLce_NYmHfCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df1.copy()                                     #Creating a copy for a possible future use\n",
        "\n",
        "!pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdZakw5JJ8Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "#x= sid.polarity_scores(sent)\n",
        "\n",
        "df1['lex_polarity']=df1['text'].apply(lambda x: sid.polarity_scores(x)['compound'] )\n",
        "df1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cocn9tM5MiGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "freq=Counter(df1['emotion'])\n",
        "freq=dict(freq)\n",
        "x= pd.DataFrame(freq,index=freq.keys())\n",
        "sns.catplot(kind='bar',data=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBlIpsCROyZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(df1['lex_polarity']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHfV7DdTQqtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sns.pairplot(df1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKDmx7evHpAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.catplot(x='emotion',y='lex_polarity',kind='violin',data=df1)\n",
        "sns.catplot(x='emotion',y='lex_polarity',kind='swarm',data=df1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbsq_4CnQ-BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_ser=pd.Series(df1['emotion'].values, dtype='category')    # Its a categorical series. That is it converts all the values.\n",
        "                                                  # within that series into numbers\n",
        "                                                  \n",
        "cat_labels=labels_ser.cat.codes \n",
        "df1['ctgr_label']=cat_labels\n",
        "df1['ind']=range(len(df1))\n",
        "#df1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WXf7ELyHpFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sns.catplot(x='lex_polarity',y='ctgr_label',data=df1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfvN9C1OeyiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.jointplot(x='ind', y=\"lex_polarity\",kind='kde', data=df1);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCGXIjr6Bw1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing modules- Removes @tags, #,(,),\\n,\\\\n,emoticons\n",
        "\n",
        "def rem_rt(string):\n",
        "  x=string.split()\n",
        "  c=0\n",
        "  for i in range(len(x)):\n",
        "    if x[i-c][0]=='@':\n",
        "      x.remove(x[i-c])\n",
        "      c+=1\n",
        "  y= ' '.join(x)\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001FFFF\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  return emoji_pattern.sub(r'', y)\n",
        "\n",
        "import re\n",
        "text=df['text'].values\n",
        "emotions=df['emotion'].values\n",
        "ntext=[]\n",
        "for sub in text:\n",
        "  x=sub.split()\n",
        "\n",
        "  sub=sub.replace(r'(','')\n",
        "  sub=sub.replace(r\")\",'')\n",
        "  sub=sub.replace(r\"\\n\",'') \n",
        "  sub=sub.replace(r\"#\",'')\n",
        "  sub=rem_rt(sub)\n",
        "  ntext.append(re.sub('\\n', '', sub)) \n",
        "\n",
        "clean_text=ntext\n",
        "clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_8tWih1k6mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['clean_text']=clean_text\n",
        "hybrid=df[['clean_text','int']].values\n",
        "hybrid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEykpHHvBw5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "vect=TfidfVectorizer()\n",
        "\n",
        "dtm=vect.fit_transform(clean_text)\n",
        "dtm_array=dtm.toarray()\n",
        "dtm_column = vect.get_feature_names()\n",
        "df_dtm=pd.DataFrame(dtm_array,columns=dtm_column)\n",
        "#df_dtm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKzWOuKRn4rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect=TfidfVectorizer()\n",
        "\n",
        "dtm=vect.fit_transform(clean_text)\n",
        "\n",
        "#print(dtm)\n",
        "\n",
        "dtm_array=dtm.toarray()\n",
        "\n",
        "dtm_column = vect.get_feature_names()\n",
        "\n",
        "df_dtm=pd.DataFrame(dtm_array,columns=dtm_column)\n",
        "\n",
        "#df_dtm['0']=df['int'].values\n",
        "\n",
        "#df_dtm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huBkYZWrBw9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test = train_test_split(clean_text, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train, y_test = train_test_split(emotions, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKUXDmkZp6k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktpZvzpOVx-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        " \n",
        "!pip install autoviml\n",
        "from autoviml.Auto_NLP import Auto_NLP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCrfI8UwVyCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "nlp_column=['text','int']\n",
        "target='emotion'\n",
        "\n",
        "train_nlp, test_nlp, nlp_transformer, preds = Auto_NLP(nlp_column, train, test, target,    #nlp_transformer- pipeline\n",
        "                                                     score_type='balanced_accuracy',\n",
        "                                                     modeltype='Classification',\n",
        "                                                     top_num_features=200, \n",
        "                                                     verbose=0, build_model=True)\n",
        "\n",
        "nlp_transformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppaBEtGIEfpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=nlp_transformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVdR9M1NJkjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "x=Pipeline(memory=None,\n",
        "         steps=[('countvectorizer',\n",
        "                 CountVectorizer(analyzer='word', binary=False,\n",
        "                                 decode_error='strict',\n",
        "                                 #dtype=<class 'numpy.int64'>,\n",
        "                                 encoding='utf-8',\n",
        "                                 input='content', lowercase=True, max_df=1.0,\n",
        "                                 max_features=8741, min_df=2,\n",
        "                                 ngram_range=(1, 1), preprocessor=None,\n",
        "                                 stop_words=None, strip_accents='unicode',\n",
        "                                 token_pattern='\\\\w{1,}', tokenizer=None,\n",
        "                                 vocabulary=None)),\n",
        "                ('multinomialnb',\n",
        "                 MultinomialNB(alpha=0.9906273994707961, class_prior=None,\n",
        "                               fit_prior=True))],\n",
        "         verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAJcrvi3GXlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Slb_N4mBxQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "#nlp_transformer.fit(X_train,y_train)\n",
        "x.fit(X_train,y_train)\n",
        "y_pred=x.predict(X_test)\n",
        "#y_pred=text_model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test,y_pred),'\\n\\n')\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred),'\\n\\n')\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNI0_gCRsE1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emo = ['anger','fear' ,'joy' ,'sadness'] \n",
        "\n",
        "def pred_emotion(string, ret=None):\n",
        "  '''\n",
        "  If you give \"ret\" as either - model_output, emotion or dict, it'll retun the same (only that).\n",
        "  But if you don't give it anything, it'll print all the values\n",
        "  '''\n",
        "  emo = ['ANGER','FEAR','JOY','SADNESS'] \n",
        "  probs=list(nlp_transformer.predict_proba([string])[0])\n",
        "\n",
        "  if ret==None:\n",
        "    print('Model output: ',nlp_transformer.predict_proba([string])[0],'\\n\\n')\n",
        "  elif ret=='model_output':\n",
        "    return nlp_transformer.predict_proba([string])[0]\n",
        "  \n",
        "  if ret==None:\n",
        "    print('The Sentence is mostly \"{}\"'.format(emo[np.argmax(probs)]),'\\n\\n')\n",
        "  elif ret=='emotion':\n",
        "    return emo[np.argmax(probs)]\n",
        "\n",
        "  emodict={k:'{:3f}%'.format(v*100) for (k,v) in zip(emo,probs)}\n",
        "  if ret==None:\n",
        "    print(emodict,'\\n')\n",
        "  elif ret=='dict':\n",
        "    return emodict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScLRrSWatxC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stri=\"I'll kill him now if I see his face!!\"\n",
        "\n",
        "pred_emotion(stri)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1oK9r32txHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stri=\"Corona is dreadful\"\n",
        "\n",
        "pred_emotion(stri)#,'emotion')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AOzmCsftxLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stri=\"He's not your true friend\"\n",
        "\n",
        "pred_emotion(stri,'dict')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8262YT-3V4DT",
        "colab_type": "text"
      },
      "source": [
        "#**Taking Twitter Data** \n",
        "By scraping from tweepy through a search keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEKfJON8WST-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZwKpBFX01tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "#!pip install langdetect\n",
        "#nltk.download('vader_lexicon')\n",
        "\n",
        "auth = tweepy.OAuthHandler('rJcIIAjv5ZrL8NKjWqPhcIkKn', 'LKX7W2BbH5XH9eU1cBanOoW5jl31Vcek18Xy4eeajTzUkH8XOj')\n",
        "\n",
        "auth.set_access_token('2832840558-2arbFHg83wp3IHDZ9Hnz2sUluIAgEKz5EOBaYi6', 'PntXRl3wopfhLL2U3JnmMJp1Wy2XqwlmuzYCZXqmtz5st')\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "#user = api.get_user('narendramodi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crt2kjf4Hspp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "topic= 'obama'            #Set the username of the user\n",
        "cnt= 100               #Set the number of tweets to be taken.\n",
        "\n",
        "#posts = api.user_timeline(screen_name = user, count = cnt, tweet_mode='extended')  #Gets all the posts of a certain user\n",
        "\n",
        "posts = api.search( topic, tweet_mode='extended',count=cnt)\n",
        "\n",
        "tweets=[]\n",
        "for i in range(len(posts)):\n",
        "  ran=posts[i]._json['full_text'].split('https')[0]   #To remove hyperlinks\n",
        "  tweets.append(ran)\n",
        "\n",
        "!pip install langdetect\n",
        "from langdetect import detect\n",
        "\n",
        "eng_tweets=[]\n",
        "for i in tweets:\n",
        "  try:\n",
        "    if detect(i)=='en':\n",
        "      s=i.split(': ')[1]\n",
        "      eng_tweets.append(s)\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "\n",
        "eng_tweets\n",
        "\n",
        "clean_tweets=[]\n",
        "for sub in eng_tweets:\n",
        "  sub=sub.replace(r'(','')\n",
        "  sub=sub.replace(r\")\",'')\n",
        "  sub=sub.replace(r\"\\n\",'')\n",
        "  sub=sub.replace(r\"#\",'')\n",
        "  sub=rem_rt(sub)\n",
        "  clean_tweets.append(re.sub('\\n', '', sub))\n",
        "\n",
        "itr=iter(clean_tweets)\n",
        "clean_tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HorDuELfn2yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Streaming and collecting tweets\n",
        "\n",
        "\n",
        "from tweepy import StreamListener\n",
        "\n",
        "class MyStreamListener(StreamListener):\n",
        "\n",
        "    def on_status(self, status):\n",
        "        \n",
        "        #return status.text\n",
        "\n",
        "        if hasattr(status,\"extended_tweet\"):\n",
        "          text = status.extended_tweet[\"full_text\"]\n",
        "        else:\n",
        "          text = status.text\n",
        "\n",
        "        print(text)\n",
        "\n",
        "        with open(\"out.csv\", \"a\", encoding='utf-8') as f:\n",
        "          #f.write(\"%s\\n\" % (text))\n",
        "          pass\n",
        "\n",
        "myStream = tweepy.Stream(auth = auth , listener=MyStreamListener())\n",
        "\n",
        "#myStream.filter(track=['trump'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIH1xfs8Xy1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samp=next(itr)\n",
        "\n",
        "print(samp,'\\n\\n')\n",
        "\n",
        "pred_emotion(samp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmsSuHRh2Nvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdT4hgRVpRNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "#!pip install langdetect\n",
        "#nltk.download('vader_lexicon')\n",
        "\n",
        "auth = tweepy.OAuthHandler('rJcIIAjv5ZrL8NKjWqPhcIkKn', 'LKX7W2BbH5XH9eU1cBanOoW5jl31Vcek18Xy4eeajTzUkH8XOj')\n",
        "\n",
        "auth.set_access_token('2832840558-2arbFHg83wp3IHDZ9Hnz2sUluIAgEKz5EOBaYi6', 'PntXRl3wopfhLL2U3JnmMJp1Wy2XqwlmuzYCZXqmtz5st')\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "#user = api.get_user('narendramodi')\n",
        "\n",
        "def scrape_tweets(topic):\n",
        "\n",
        "  topics= topic           #Set the username of the user\n",
        "  cnt= 50            #Set the number of tweets to be taken.\n",
        "\n",
        "  #posts = api.user_timeline(screen_name = user, count = cnt, tweet_mode='extended')  #Gets all the posts of a certain user\n",
        "\n",
        "  posts = api.search( topics, tweet_mode='extended',count=cnt)\n",
        "\n",
        "  tweets=[]\n",
        "  for i in range(len(posts)):\n",
        "    ran=posts[i]._json['full_text'].split('https')[0]   #To remove hyperlinks\n",
        "    tweets.append(ran)\n",
        "\n",
        "  from langdetect import detect\n",
        "\n",
        "  eng_tweets=[]\n",
        "  for i in tweets:\n",
        "    try:\n",
        "      if detect(i)=='en':\n",
        "        s=i.split(': ')[1]\n",
        "        eng_tweets.append(s)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  eng_tweets\n",
        "\n",
        "  clean_tweets=[]\n",
        "  for sub in eng_tweets:\n",
        "    sub=sub.replace(r'(','')\n",
        "    sub=sub.replace(r\")\",'')\n",
        "    sub=sub.replace(r\"\\n\",'')\n",
        "    sub=sub.replace(r\"#\",'')\n",
        "    sub=rem_rt(sub)\n",
        "    clean_tweets.append(re.sub('\\n', '', sub))\n",
        "\n",
        "  itr=iter(clean_tweets)\n",
        "\n",
        "  return clean_tweets\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V1yiZcO8Bh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scrape_tweets('trump')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aghvOAwc4Hd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tweet_analysis(key):\n",
        "\n",
        "    tweet=scrape_tweets(key)[0]\n",
        "    emo=pred_emotion(tweet,'dict')\n",
        "    return emo\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNRjogKo4KBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emo=tweet_analysis('dread')\n",
        "emo"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
